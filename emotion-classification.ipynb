{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 微博情感分析"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch.nn.functional as F \n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torchtext.vocab as Vocab\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime"
   ]
  },
  {
   "source": [
    "## 数据介绍\n",
    "\n",
    "0喜悦\n",
    "1愤怒\n",
    "2厌恶\n",
    "3低落"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=np.load(\"dictionary.npy\",allow_pickle=True)\n",
    "#torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_encode():\n",
    "    y=[int(line) for line in open(\"labels.txt\", encoding=\"utf-8\").readlines()]\n",
    "    y=np.expand_dims(np.array(y),1)\n",
    "    encoder=OneHotEncoder()\n",
    "    return encoder.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=labels_encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_encode(X):\n",
    "    for i in range(len(X)):\n",
    "        X[i]=[np.int64(dictionary.item()[j]) for j in X[i]]\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[line.split() for line in open(\"texts.txt\",encoding=\"utf-8\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=texts_encode(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(X,length):\n",
    "    for key,value in enumerate(X):\n",
    "        if len(value)<=length:\n",
    "            X[key]=value+[0 for i in range (length-len(value))]\n",
    "        else:\n",
    "            X[key]=X[key][:length]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(cut(X,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn_simple(nn.Module):\n",
    "    def __init__(self,vocab,embed_size,num_hiddens,num_layers):\n",
    "        super(Rnn_simple,self).__init__()\n",
    "        self.embedding=nn.Embedding((vocab),embed_size)\n",
    "        self.encoder=nn.LSTM(input_size=embed_size,hidden_size=num_hiddens,num_layers=num_layers,bidirectional=True)\n",
    "        self.decoder=nn.Linear(4*num_hiddens,4)\n",
    "    def forward(self,X):\n",
    "        X=self.embedding(X.permute(1,0))\n",
    "        X,_=self.encoder(X)\n",
    "        X=torch.cat((X[0],X[-1]),-1)\n",
    "        X=self.decoder(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab,embed_size,num_hiddens,num_layers=len(dictionary.item())+1,100,100,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Rnn_simple(vocab,embed_size,num_hiddens,num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Rnn_simple(\n",
       "  (embedding): Embedding(24759, 100)\n",
       "  (encoder): LSTM(100, 100, num_layers=2, bidirectional=True)\n",
       "  (decoder): Linear(in_features=400, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.LongTensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0009, -0.0294,  0.0336, -0.0037],\n",
       "        [-0.0116,  0.0006,  0.0382, -0.0136],\n",
       "        [-0.0135,  0.0070,  0.0373, -0.0358],\n",
       "        ...,\n",
       "        [-0.0202, -0.0179,  0.0555, -0.0178],\n",
       "        [-0.0383, -0.0116,  0.0644, -0.0483],\n",
       "        [ 0.0044, -0.0294,  0.0552, -0.0102]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def evaluate(valdata,vallabel):\n",
    "        ans=0.;\n",
    "        with torch.no_grad():\n",
    "            prelabel=network(valdata)\n",
    "            for i in range(len(prelabel)):\n",
    "                if vallabel[i][torch.argmax(prelabel[i])]==1:\n",
    "                    ans+=1\n",
    "        print(\"the accuracy is\",ans/float(len(prelabel)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainloop( n_epochs,dataloader,network,optim,loss_fn):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        #evaluate(mask_data.data,mask_data.label)\n",
    "        loss_train = 0.0\n",
    "        evaluate(X,torch.Tensor(y))\n",
    "        for input, realout in dataloader:\n",
    "            predictout = network(input)\n",
    "\n",
    "            loss = loss_fn(predictout, realout)\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            loss_train += loss.item()\n",
    "            #if epoch == 1 or epoch % 100 == 0:\n",
    "        print(\n",
    "                f'{datetime.datetime.now()} epoch {epoch} training loss {loss_train/len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=50\n",
    "network=net\n",
    "optim=torch.optim.Adam(network.parameters(),lr=0.01)\n",
    "dataset=TensorDataset(X,torch.Tensor(y))\n",
    "dataloader=DataLoader(dataset,batch_size=300,shuffle=True)\n",
    "loss_fn=nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the accuracy is 0.14483139856274185\n",
      "2020-11-28 21:49:12.889386 epoch 1 training loss 0.5243786917282984\n",
      "the accuracy is 0.5514096185737977\n",
      "2020-11-28 21:49:18.572848 epoch 2 training loss 0.4582063624492058\n",
      "the accuracy is 0.6160862354892206\n",
      "2020-11-28 21:49:24.303086 epoch 3 training loss 0.3573974623129918\n",
      "the accuracy is 0.6915422885572139\n",
      "2020-11-28 21:49:30.615241 epoch 4 training loss 0.2570456014229701\n",
      "the accuracy is 0.8253178551686015\n",
      "2020-11-28 21:49:37.577732 epoch 5 training loss 0.1704218742939142\n",
      "the accuracy is 0.9333886124930901\n",
      "2020-11-28 21:49:44.621048 epoch 6 training loss 0.08517060772730754\n",
      "the accuracy is 0.9781647318960752\n",
      "2020-11-28 21:49:50.970137 epoch 7 training loss 0.03618166006456774\n",
      "the accuracy is 0.9919845218352681\n",
      "2020-11-28 21:49:57.406990 epoch 8 training loss 0.015587578993290663\n",
      "the accuracy is 0.9975124378109452\n",
      "2020-11-28 21:50:03.821116 epoch 9 training loss 0.00611537210464191\n",
      "the accuracy is 0.9980652294085129\n",
      "2020-11-28 21:50:10.387632 epoch 10 training loss 0.002841393705099248\n",
      "the accuracy is 0.9997236042012161\n",
      "2020-11-28 21:50:17.522242 epoch 11 training loss 0.0013981621864681633\n",
      "the accuracy is 1.0\n",
      "2020-11-28 21:50:24.479801 epoch 12 training loss 0.000520797519129701\n",
      "the accuracy is 1.0\n",
      "2020-11-28 21:50:31.790002 epoch 13 training loss 0.00035527793583101954\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-5b47d3faf95f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-0f4db571f0c4>\u001b[0m in \u001b[0;36mtrainloop\u001b[1;34m(n_epochs, dataloader, network, optim, loss_fn)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;31m#evaluate(mask_data.data,mask_data.label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealout\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mpredictout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-53d2e14c39a9>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(valdata, vallabel)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprelabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaldata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprelabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mvallabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprelabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                 \u001b[0mans\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"the accuracy is\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprelabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainloop(n_epochs,dataloader,network,optim,loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}