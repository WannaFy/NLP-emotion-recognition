{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 微博情感分析"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch.nn.functional as F \n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torchtext.vocab as Vocab\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime"
   ]
  },
  {
   "source": [
    "## 数据介绍\n",
    "\n",
    "0喜悦\n",
    "1愤怒\n",
    "2厌恶\n",
    "3低落"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=np.load(\"dictionary.npy\",allow_pickle=True)\n",
    "#torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_encode():\n",
    "    y=[int(line) for line in open(\"labels.txt\", encoding=\"utf-8\").readlines()]\n",
    "    y=np.expand_dims(np.array(y),1)\n",
    "    encoder=OneHotEncoder()\n",
    "    return encoder.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=labels_encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_encode(X):\n",
    "    for i in range(len(X)):\n",
    "        X[i]=[np.int64(dictionary.item()[j]) for j in X[i]]\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[line.split() for line in open(\"texts.txt\",encoding=\"utf-8\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=texts_encode(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(X,length):\n",
    "    for key,value in enumerate(X):\n",
    "        if len(value)<=length:\n",
    "            X[key]=value+[0 for i in range (length-len(value))]\n",
    "        else:\n",
    "            X[key]=X[key][:length]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(cut(X,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn_simple(nn.Module):\n",
    "    def __init__(self,vocab,embed_size,num_hiddens,num_layers):\n",
    "        super(Rnn_simple,self).__init__()\n",
    "        self.embedding=nn.Embedding((vocab),embed_size)\n",
    "        self.encoder=nn.LSTM(input_size=embed_size,hidden_size=num_hiddens,num_layers=num_layers,bidirectional=True)\n",
    "        self.decoder=nn.Linear(4*num_hiddens,4)\n",
    "    def forward(self,X):\n",
    "        X=self.embedding(X.permute(1,0))\n",
    "        X,_=self.encoder(X)\n",
    "        X=torch.cat((X[0],X[-1]),-1)\n",
    "        X=self.decoder(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab,embed_size,num_hiddens,num_layers=len(dictionary.item())+1,100,100,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Rnn_simple(vocab,embed_size,num_hiddens,num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Rnn_simple(\n",
       "  (embedding): Embedding(24759, 100)\n",
       "  (encoder): LSTM(100, 100, num_layers=2, bidirectional=True)\n",
       "  (decoder): Linear(in_features=400, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.LongTensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0009, -0.0294,  0.0336, -0.0037],\n",
       "        [-0.0116,  0.0006,  0.0382, -0.0136],\n",
       "        [-0.0135,  0.0070,  0.0373, -0.0358],\n",
       "        ...,\n",
       "        [-0.0202, -0.0179,  0.0555, -0.0178],\n",
       "        [-0.0383, -0.0116,  0.0644, -0.0483],\n",
       "        [ 0.0044, -0.0294,  0.0552, -0.0102]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def evaluate(valdata,vallabel):\n",
    "        ans=0.;\n",
    "        with torch.no_grad():\n",
    "            prelabel=network(valdata)\n",
    "            for i in range(len(prelabel)):\n",
    "                if prelabel[i][0]>=0.5 and int(vallabel[i][0])==1:\n",
    "                    ans+=1\n",
    "                if prelabel[i][0]<0.5 and int(vallabel[i][0])==0:\n",
    "                    ans+=1\n",
    "        print(\"the accuracy is\",ans/float(len(prelabel)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainloop( n_epochs,dataloader,network,optim,loss_fn):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        #evaluate(mask_data.data,mask_data.label)\n",
    "        loss_train = 0.0\n",
    "        for input, realout in dataloader:\n",
    "            predictout = network(input)\n",
    "\n",
    "            loss = loss_fn(predictout, realout)\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            loss_train += loss.item()\n",
    "            #if epoch == 1 or epoch % 100 == 0:\n",
    "        print(\n",
    "                f'{datetime.datetime.now()} epoch {epoch} training loss {loss_train/len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=50\n",
    "network=net\n",
    "optim=torch.optim.Adam(network.parameters(),lr=0.001)\n",
    "dataset=TensorDataset(X,torch.Tensor(y))\n",
    "dataloader=DataLoader(dataset,batch_size=300,shuffle=True)\n",
    "loss_fn=nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-5b47d3faf95f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-84-fef7cbd20359>\u001b[0m in \u001b[0;36mtrainloop\u001b[1;34m(n_epochs, dataloader, network, optim, loss_fn)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m#if epoch == 1 or epoch % 100 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         print(\n\u001b[1;32m---> 17\u001b[1;33m                 f'{datetime.datetime.now()} epoch {epoch} training loss {loss_train/len(dataloader)}')\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "trainloop(n_epochs,dataloader,network,optim,loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}